{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress, get_worker\n",
    "import os\n",
    "import binascii\n",
    "\n",
    "# Replace with IP address of the dask scheduler\n",
    "client = Client(\"tcp://131.180.106.138:8786\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "BATCH_SIZES = [100,500,1000,1500,2000]\n",
    "XCLBIN_PATH = \"a.xclbin\"\n",
    "PLATFORM = \"alveo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-01 17:23:59--  https://raw.githubusercontent.com/modestyachts/CIFAR-10.1/master/datasets/cifar10.1_v4_data.npy\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6208640 (5.9M) [application/octet-stream]\n",
      "Saving to: ‘cifar10.1_v4_data.npy.10’\n",
      "\n",
      "100%[======================================>] 6,208,640   --.-K/s   in 0.1s    \n",
      "\n",
      "2020-11-01 17:24:00 (51.7 MB/s) - ‘cifar10.1_v4_data.npy.10’ saved [6208640/6208640]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download the CIFAR 10 dataset \n",
    "!wget https://raw.githubusercontent.com/modestyachts/CIFAR-10.1/master/datasets/cifar10.1_v4_data.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_worker(ibuf_normal, index):\n",
    "    from multiprocessing import Process,Queue\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    def forked_process(queue, ibuf_normal):\n",
    "        from driver import FINNAccelDriver\n",
    "        from pynq.ps import Clocks\n",
    "        finnDriver = FINNAccelDriver(len(ibuf_normal), XCLBIN_PATH, PLATFORM)\n",
    "        ibuf_folded = finnDriver.fold_input(ibuf_normal)\n",
    "        ibuf_packed = finnDriver.pack_input(ibuf_folded)\n",
    "        finnDriver.copy_input_data_to_device(ibuf_packed)\n",
    "        finnDriver.execute()\n",
    "        obuf_packed = np.empty_like(finnDriver.obuf_packed_device)\n",
    "        finnDriver.copy_output_data_from_device(obuf_packed)\n",
    "        obuf_folded = finnDriver.unpack_output(obuf_packed)\n",
    "        obuf_normal = finnDriver.unfold_output(obuf_folded)\n",
    "        \n",
    "        if PLATFORM != \"alveo\":\n",
    "            fclk_mhz = Clocks.fclk0_mhz\n",
    "        else:\n",
    "            fclk_mhz = finnDriver.fclk_mhz\n",
    "        queue.put((obuf_normal, fclk_mhz))\n",
    "    \n",
    "    \n",
    "    # We need to run the Pynq overlay in a new forked process since it cannot be run in a non-Main thread    \n",
    "    t0 = time.time()\n",
    "    queue = Queue()\n",
    "    p = Process(target=forked_process, args=(queue, ibuf_normal))\n",
    "    p.start()\n",
    "    result, fclk_mhz = queue.get()\n",
    "    p.join()\n",
    "    t1 = time.time()\n",
    "    print(\"EXECUTION TIME ON THIS WORKER (s): \", t1 - t0)\n",
    "    return {\n",
    "        'data': result,\n",
    "        'time': t1 - t0,\n",
    "        'index': index,\n",
    "        'fclk_mhz': fclk_mhz\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 100\n",
      "Received data from workers.\n",
      "{'runtime[ms]': 17267.237186431885, 'throughput[images/s]': 5.791314436717022, 'DRAM_in_bandwidth[Mb/s]': 0.01779091794959469, 'DRAM_out_bandwidth[Mb/s]': 5.791314436717022e-06, 'fclk[mhz]': 100.0, 'N': 100}\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "num_of_workers = len(client.scheduler_info()[\"workers\"])\n",
    "full_cifar = np.load('cifar10.1_v4_data.npy')\n",
    "\n",
    "\n",
    "for BATCH_SIZE in BATCH_SIZES:\n",
    "    print(\"BATCH_SIZE:\", BATCH_SIZE)\n",
    "    partial_cifar = full_cifar[:BATCH_SIZE]\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Split up the file into equal sized chunks based on number of available dask workers\n",
    "    data_split = []\n",
    "    start = 0\n",
    "    chunk_size = int(len(partial_cifar)/num_of_workers)\n",
    "    for i in range(num_of_workers - 1):\n",
    "        data_split.append(partial_cifar[start: start+chunk_size])\n",
    "        start += chunk_size\n",
    "    data_split.append(partial_cifar[start:]) #Last partition\n",
    "\n",
    "    # Scatter the data to the workers before calling run_on_worker on the workers\n",
    "    distributed_data = client.scatter(data_split)\n",
    "    futures = client.map(run_on_worker, distributed_data, range(num_of_workers))\n",
    "    results = client.gather(futures)\n",
    "    print(\"Received data from workers.\")\n",
    "\n",
    "    # Reorder the response based on original input order\n",
    "    results.sort(key = lambda result: result['index'])  \n",
    "\n",
    "    # Concatenate the result where each is an ndarray of the shape (BATCH_SIZE/num_of_workers, 1)\n",
    "    merged_result = np.concatenate([r['data'] for r in results]) # FINAL RESULTS (CLASS LABELS)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    runtime = t1 - t0\n",
    "    res = {}\n",
    "    res[\"runtime[ms]\"] = runtime*1000\n",
    "    res[\"throughput[images/s]\"] = BATCH_SIZE / runtime\n",
    "    res[\"DRAM_in_bandwidth[Mb/s]\"] = np.prod((BATCH_SIZE, 32, 32, 1, 3))*0.000001 / runtime\n",
    "    res[\"DRAM_out_bandwidth[Mb/s]\"] = np.prod((BATCH_SIZE, 1, 1))*0.000001 / runtime\n",
    "    res[\"fclk[mhz]\"] = results[0]['fclk_mhz']\n",
    "    res[\"N\"] = BATCH_SIZE\n",
    "    print(res)\n",
    "    print(\"**************************\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
